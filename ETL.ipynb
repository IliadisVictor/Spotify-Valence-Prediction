{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976a33c3",
   "metadata": {},
   "source": [
    "# Dissecting Spotify Valence - ETL\n",
    "In this assignment i will try to dissect Spotify's Valence metric this is the data ETL file.\n",
    "\n",
    "---\n",
    "\n",
    "> Iliadis Viktoras, Undergraduate Student <br />\n",
    "> Department of Management Science and Technology <br />\n",
    "> Athens University of Economics and Business <br />\n",
    "> iliadisviktoras@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa2d4e7",
   "metadata": {},
   "source": [
    "For cleaner code i decided to split the files , in this file we will extract the charts from zenodo , and use the spotify API and the spotipy library to get each song's audio features and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9217a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690def04",
   "metadata": {},
   "source": [
    "### Extracting to a DF the Zenodo Data\n",
    "We select the charts.zip from:\n",
    "* The [Zenodo](https://zenodo.org/record/4778563#.YgAF4bpBy3A) dataset from the spotify_anova class file with 2017-2019 charts.\n",
    "I will copy the process from the spotify_anova example , except some features i find to be redundant for the purpose of this analysis . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ba9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 0\n",
    "dfs = []\n",
    "for file in glob.glob('Charts/*/201?/*.csv'):\n",
    "    weekly_chart = pd.read_csv(file, header=header, sep='\\t')\n",
    "    dfs.append(weekly_chart)\n",
    "all_charts = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea1101c",
   "metadata": {},
   "source": [
    "#### Spotify API\n",
    "In order to get each track's audio feature and analysis , we need to set up our Spotify API.\n",
    "You can do the same in [Spotify for Developers](https://developer.spotify.com/).\n",
    "We also create a file to store the credential's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f07c6f",
   "metadata": {},
   "source": [
    "```\n",
    "config = {\n",
    "    'client_id' : 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX',\n",
    "    'client_secret' :'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "}\n",
    "```\n",
    "* We will get, for each of the top-streaming tracks, its [Track features](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-several-audio-features) and its [Audio Analysis](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-audio-analysis) . \n",
    "* To do that, we'll create a dictionary keyed by `song_id`, with values being the audio features for the specific track.\n",
    "* [Spotipy Documentation](https://spotipy.readthedocs.io/en/2.19.0/) , for all the functions called . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ee8f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotify_config import config\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(config['client_id'],\n",
    "                                                      config['client_secret'])\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "all_track_ids = list(all_charts['song_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee31805e",
   "metadata": {},
   "source": [
    "* We start with the audio features , using the API's functions that intakes up to 100 Id's at a time .\n",
    "* To do that we create a dictionary keyed by `song_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43cb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "all_track_ids = list(all_charts['song_id'].unique())\n",
    "\n",
    "start = 0\n",
    "num_tracks = 100\n",
    "while start < len(all_track_ids):\n",
    "    tracks_batch = all_track_ids[start:start+num_tracks]\n",
    "    features_batch = sp.audio_features(tracks_batch)\n",
    "    features.update({ track_id : track_features \n",
    "                     for track_id, track_features in zip(tracks_batch, features_batch) })\n",
    "    start += num_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a222f1",
   "metadata": {},
   "source": [
    "* We turn the dictionary into a Dataframe\n",
    "* We keep only the features that offer info on the track "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.DataFrame.from_dict(features, orient='index')\n",
    "tracks = tracks.drop(['type','id','uri','track_href','analysis_url'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6225aebb",
   "metadata": {},
   "source": [
    "* We continue with the audio analysis  \n",
    "Unfortunately unlike the audio features  that we can do batches of 100's , the audio analysis must be extracted track by track , that takes a significant amount of time , so we will do it once and then export the joined data into a csv to be able to speed up the process . The code will be kept for documentation purposes . \n",
    "\n",
    "**From the Audio analysis we keep for each unique song :** \n",
    "* The amount of segments and  sections  , perharps the consistency or inconsistency of the sound has something to do with the valence , we only considered the ones with a confidence of 0.3 and greater .\n",
    "* The average dominance of each the 12 pitches across all segments for each song . \n",
    "* The average  for the 12 values of timbre , we are going to try and use them independently and summed . \n",
    "* Tatums average duration , i found that tatums was heavily used in the development of  Echo Nest's algorithms .   \n",
    "\n",
    "For each of the features i mentioned above we create the corresponding function , with the audio analysis as input we extracted with the help of spotipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f0bb54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates for each of the 12 pitch's the avg across the track's segments\n",
    "def CalcPitch(song_analysis):\n",
    "    # we create an empty list to store for each pitch it's value\n",
    "    pitchesvalues =[0] * 12\n",
    "    Totalvalues = 0 \n",
    "    # we iterate all different segments\n",
    "    for index in range(len(song_analysis['segments'])):\n",
    "        if (song_analysis['segments'][index]['confidence'] >0.3):\n",
    "            Totalvalues += 1 \n",
    "            counter = 0 \n",
    "        # we sum for all the different segments each pitch's value\n",
    "            for pitch in song_analysis['segments'][index]['pitches']:\n",
    "                pitchesvalues[counter] += pitch\n",
    "                counter +=1\n",
    "    # we get the average pitch's value for the whole song by diving with the amount of total segments        \n",
    "    pitchesvalues[:] = [x / Totalvalues for x in pitchesvalues]        \n",
    "# returns an array of 12 values , for the avg of the 12 pitch's across all segments\n",
    "    return pitchesvalues\n",
    "\n",
    "def CalcTimbre(song_analysis):\n",
    "    # we create an empty list to store for each pitch it's value\n",
    "    Timbrevalues =[0] * 12\n",
    "    Totalvalues = 0 \n",
    "    # we iterate all different segments\n",
    "    for index in range(len(song_analysis['segments'])):\n",
    "        if (song_analysis['segments'][index]['confidence'] >0.3):\n",
    "            Totalvalues += 1\n",
    "            counter = 0 \n",
    "        # we sum for all the different segments each timbre's value\n",
    "            for timbre in song_analysis['segments'][index]['timbre']:\n",
    "                Timbrevalues[counter] += timbre\n",
    "                counter +=1\n",
    "    # we get the average pitch's value for the whole song by diving with the amount of total segments        \n",
    "    Timbrevalues[:] = [x / Totalvalues for x in Timbrevalues]        \n",
    "# returns an array of 12 values , for the avg of the 12 timbres's across all segments\n",
    "    return Timbrevalues\n",
    "\n",
    "\n",
    "# Calculates the average tatum duration \n",
    "\n",
    "def AVGTatum(song_analysis):\n",
    "    tatumsum = 0 \n",
    "#     for each of the available tatums\n",
    "    countvalues = 0 \n",
    "    for index in range(len(song_analysis['tatums'])):\n",
    "        if (song_analysis['tatums'][index]['confidence'] >0.3):\n",
    "            countvalues +=1\n",
    "#    we sum every duration\n",
    "            tatumsum += song_analysis['tatums'][index]['duration']\n",
    "#    we divided by the amount of tatums to get the avg duration     \n",
    "    tatumavg = tatumsum / countvalues\n",
    "    return round(tatumavg,4)\n",
    "\n",
    "# Calculates the total amount of segments in 1 track , recognizing only the ones with a confidence greater than point 3\n",
    "def TotalSegments(song_analysis):\n",
    "    sumsegments = 0 \n",
    "    for index in range(len(song_analysis['segments'])):\n",
    "        if (song_analysis['segments'][index]['confidence'] > 0.3):\n",
    "            sumsegments += 1\n",
    "    return sumsegments\n",
    "\n",
    "# Calculates the total amount of sections in 1 track , recognizing only the ones with a confidence greated than point 3 \n",
    "def TotalSections(song_analysis):\n",
    "    sumsections = 0 \n",
    "    for index in range(len(song_analysis['sections'])):\n",
    "        if (song_analysis['sections'][index]['confidence'] > 0.3):\n",
    "            sumsections += 1\n",
    "    return sumsections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb31431",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = {}\n",
    "counter = 0\n",
    "while counter < len(all_track_ids):\n",
    "#     select an id from the 13880 unique ones\n",
    "    track = all_track_ids[counter]\n",
    "# get the tracks track analysis from the api     \n",
    "    song_analysis = sp.audio_analysis(track)\n",
    "\n",
    "# Now we use the functions we created and calculate the features for all unique id's \n",
    "    EngineeredFeatures = {}\n",
    "    EngineeredFeatures['TotalSegments'] = TotalSegments(song_analysis)\n",
    "    EngineeredFeatures['TotalSections'] = TotalSections(song_analysis)   \n",
    "    EngineeredFeatures['AvgTatumDuration'] = AVGTatum(song_analysis)\n",
    "# We get the 12 values for Pitch and Timbre\n",
    "    Pitch12 = CalcPitch(song_analysis)\n",
    "    Timbre12 = CalcTimbre(song_analysis)\n",
    "    for index in range(len(Pitch12)):\n",
    "        EngineeredFeatures['Pitch'+str(index+1)] = Pitch12[index]\n",
    "    for index in range(len(Pitch12)):\n",
    "        EngineeredFeatures['Timbre'+str(index+1)] = Timbre12[index]\n",
    "  \n",
    "    analysis.update({ track: EngineeredFeatures })\n",
    "    counter += 1\n",
    "analysisDF = pd.DataFrame.from_dict(analysis, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ba8d2",
   "metadata": {},
   "source": [
    "Now we join the features from the audio features and the audio analysis , and export it to csv to use it in our analysis in the notebook . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "JoinedDF = tracks.join(analysisDF)\n",
    "JoinedDF.to_csv(\"TrackFeatures.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
